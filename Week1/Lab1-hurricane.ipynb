{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08d45d18-d45b-43a3-95e4-2696e99f5f77",
   "metadata": {},
   "source": [
    "# EDS232 Lab 1: Regression\n",
    "\n",
    "## Overview\n",
    "In this lab, we will introduce the basics of machine learning in **Python** with **regression** algorithms, a core technique used to predict continuous outcomes. We will use the popular **scikit-learn** library, which provides easy-to-use tools for building and evaluating machine learning models.\n",
    "\n",
    "Specifically, we will learn how regression algorithms can help us model and predict water quality data.\n",
    "\n",
    "## Objectives\n",
    "By the end of this lab, you will be able to:\n",
    "- Understand the concept of regression \n",
    "- Implement regression models in Python\n",
    "- Evaluate model performance using  **R²** and **MSE**\n",
    "- Visualize regression prediction results \n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- **Regression**: A machine learning method for predicting continuous values.\n",
    "  - **Simple Linear Regression**: A regression model with one independent variable.\n",
    "  - **Polynomial Regression**: A regression model which models the relationship between X and Y as an n-degree polynomial.\n",
    "  \n",
    "- **Scikit-learn**: A Python library that provides simple and efficient tools for data mining and machine learning. We will use it for:\n",
    "  - **Data Preprocessing**: Preparing data for the model.\n",
    "  - **Model Training**: Fitting the regression model to our data.\n",
    "  - **Model Evaluation**: Assessing model performance using model evaluation metrics.\n",
    "\n",
    "- **Model Evaluation Metrics**: Tools to assess how well our model fits the data, such as:\n",
    "  - **R² (R-squared)**: Measures the proportion of variance in the dependent variable that is predictable from the independent variable(s).\n",
    "  - **MSE (Mean Square Error)**: The average squared differences between predicted and actual values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d5ef3b-fdef-4d7d-b3d2-bd4ba3b080a1",
   "metadata": {},
   "source": [
    "### About the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da63da6-2263-42e0-97e1-8186e5020bf2",
   "metadata": {},
   "source": [
    "Hurricane Irene caused extensive flood and wind damage as it traveled across the Caribbean and up the East coast of the United States.  The Hurricane made landfall in the United States near Cape Lookout, North Carolina on August 27th, 2011 and was downgraded to a Tropical Storm by the time it hit the New York City region on Sunday, August 28th, 2011.\n",
    "\n",
    "A dataset from the Hudson River Environmental Conditions Observing System (HRECOS) offers a detailed look at the effects of Hurricane Irene on the river's ecosystem through high-frequency, 15-minute interval measurements over a ten-day period. It includes variables critical to understanding ecological health, such as water temperature, dissolved oxygen, turbidity, depth, and meteorological data like rainfall and wind speed. Analyzing these variables helps answer questions about how extreme weather events like hurricanes can disrupt river ecosystems and impact water quality.\n",
    "**You can access the data and metadata [here](https://www.caryinstitute.org/eco-inquiry/hudson-data-jam-competition/datasets/hurricane-irene-and-hudson-river).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7e6ccf-0e23-461a-92de-33fb1d57f5ee",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries and load data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c13825-317d-4a03-8acd-79afa32e8c99",
   "metadata": {},
   "source": [
    "#### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8750236-65ab-42f3-ab22-763eb6d22161",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import sklearn.linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a050dbf3-9160-4abe-a394-6f34e31f6bcf",
   "metadata": {},
   "source": [
    "#### Load the data\n",
    "\n",
    "Turbidity levels in water can be significantly affected by major weather events such as hurricanes. Turbidity measures how much light is blocked by particles in water. In an event like a hurricane, we expect wind and rainfall to bring in suspended particles, increasing the turbidity of the water. When light is blocked by particles in water, oxygen production is impacted as well. When a natural disaster like a hurricane alters turbidity levels in a body of water, how is dissolved oxygen  impacted? Let's find out. \n",
    "\n",
    "In this lab, we are interested in the turbidity and dissolved oxygen variables. Read the data into the `hurricane_do` and `hurricane_turbidity` variables. Then, merge these two dataframes. Store the result in the `df` variable. Drop the columns that contain data for Piermont, as Piermont does not contain any turbidity data. We are only interested in the Port of Albany and Norrie Point for this lab. \n",
    "\n",
    "*Notice that the data is not a csv file and is instead a **.xlsx** file! Use the `pandas.read_excel` function to read in your data. You can find more documentation on reading in .xlsx files [here](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ab66393-bbdb-4c7b-8bd9-81bbb7c83958",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/scarroll/MEDS/EDS232-labs/Week1'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40a08889-652c-498a-b5d4-60bf65ba2f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fp = os.path.join('data/Hurricane_Irene_and_the_Hudson_River.xlsx')\n",
    "hurricane_do = pd.read_excel(fp, sheet_name = 5)\n",
    "hurricane_turbidity = pd.read_excel(fp, sheet_name = 2)\n",
    "df = pd.merge(hurricane_do, hurricane_turbidity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70a3f96-267d-4f9c-88fd-5e7011d0e307",
   "metadata": {},
   "source": [
    "### Step 2: Explore  and clean the data\n",
    "\n",
    "Do some initial exploratory analysis on the data. Check out what type of data you are working with, and plot your data. Write a few sentences on your findings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4daa3b40-8260-409f-9116-2b7e1bb01f28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time (ET)</th>\n",
       "      <th>Port of Albany D.O. (ppm)</th>\n",
       "      <th>Norrie Point D.O. (ppm)</th>\n",
       "      <th>Piermont D.O. (ppm)</th>\n",
       "      <th>Port of Albany Turbidity in NTU</th>\n",
       "      <th>Norrie Point Turbidity in NTU</th>\n",
       "      <th>Piermont Turbidity in NTU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-08-25 00:00:00</td>\n",
       "      <td>7.68</td>\n",
       "      <td>7.81</td>\n",
       "      <td>no data available</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>no data available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-08-25 00:15:00</td>\n",
       "      <td>7.60</td>\n",
       "      <td>7.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-08-25 00:30:00</td>\n",
       "      <td>7.57</td>\n",
       "      <td>7.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.3</td>\n",
       "      <td>7.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date Time (ET)   Port of Albany D.O. (ppm)  Norrie Point D.O. (ppm)  \\\n",
       "0 2011-08-25 00:00:00                        7.68                     7.81   \n",
       "1 2011-08-25 00:15:00                        7.60                     7.73   \n",
       "2 2011-08-25 00:30:00                        7.57                     7.63   \n",
       "\n",
       "  Piermont D.O. (ppm)   Port of Albany Turbidity in NTU  \\\n",
       "0   no data available                               4.0   \n",
       "1                 NaN                               3.9   \n",
       "2                 NaN                               4.3   \n",
       "\n",
       "   Norrie Point Turbidity in NTU Piermont Turbidity in NTU  \n",
       "0                            9.3         no data available  \n",
       "1                            8.4                       NaN  \n",
       "2                            7.9                       NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cedcc8bc-ab28-452d-8417-85a54f36e298",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date Time (ET)                      datetime64[ns]\n",
       " Port of Albany D.O. (ppm)                 float64\n",
       "Norrie Point D.O. (ppm)                    float64\n",
       "Piermont D.O. (ppm)                         object\n",
       " Port of Albany Turbidity in NTU           float64\n",
       "Norrie Point Turbidity in NTU              float64\n",
       "Piermont Turbidity in NTU                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b43b5c6-b86b-41c4-b7fe-cd8422023fb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date Time (ET)                         0\n",
       " Port of Albany D.O. (ppm)             0\n",
       "Norrie Point D.O. (ppm)                0\n",
       "Piermont D.O. (ppm)                 1151\n",
       " Port of Albany Turbidity in NTU       0\n",
       "Norrie Point Turbidity in NTU          0\n",
       "Piermont Turbidity in NTU           1151\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9635e119-c988-4acd-b4c3-9580121cd0e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543b5386-9b1f-4730-a818-8f6efc1c6fca",
   "metadata": {},
   "source": [
    "To explore the data I first viewed the first three lines of with `head()`. I then found the dtaa types of each column of data with `dtypes`, which appear normal. Then I found any NA values on each column, which also correspond correctly. Lastly, I found the dimensions of the df with `shape`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5e859-39ca-4f92-8147-190ca61c5f6a",
   "metadata": {},
   "source": [
    "When you were exploring the data, you may have noticed that the column names aren't the cleanest. Update the column names to the following : `date`, `albany_DO`, `norrie_DO`, `albany_turbidity`, `norrie_turbidity` (**make sure your column names are in that order!!**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28f96e1-adb2-4aba-9194-7563c1eea328",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df # Check to make sure column names were updated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599506da-4fe1-4abd-8ec3-f69842cf93d7",
   "metadata": {},
   "source": [
    "### Step 3: Prepare the data for machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e8fa3c-a09d-4fac-ab66-4add0d6254a4",
   "metadata": {},
   "source": [
    "It is time to split our data into training and testing data for our linear regression model. The `train_test_split` function from the `sklearn.model_selection` module will let us accomplish this.\n",
    "\n",
    "The `train_test_split` function takes two inputs: X and Y, and produces four outputs: X_train, X_test, Y_train, and Y_test.  It also takes two parameters, `test_size`, which specifies the proportion of data to be used in the testing set and `random_state`.\n",
    "\n",
    "This process allows us to train the model on a subset of the data (training set) and then evaluate its performance and generalizability on unseen data (testing set). By doing this, we can assess how well the model predicts dissolved oxygen levels based on turbidity after a storm. \n",
    "\n",
    "Select your data such that `albany_turbidity` is your feature or independent variable (X) and `albany_DO` is your target or dependent variable (Y). Then split it using `train_test_split`.\n",
    "\n",
    " **Use a test size of 0.33 and a random state of 42**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d728ab-ead2-41fc-8aea-45a7859a629b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select features and target\n",
    "X = ...\n",
    "Y = ...\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = ... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217f625b-c0bd-4475-b39f-168a51a48360",
   "metadata": {},
   "source": [
    "### Step 4: Select your model\n",
    "\n",
    "We are going to use linear regression to predict the turbidity in Albany. Is linear regression a good model to pick to achieve this goal? Answer in the markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a64c8-961f-4fec-a58b-36f56b2ba623",
   "metadata": {},
   "source": [
    "*Your answer here*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185639e3-9147-4aec-ad24-51975747be11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize and fit the model\n",
    "model = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81a4229-21e3-452a-bfd4-90f7570623e3",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate the model\n",
    "\n",
    "Now it's time to see how well our model does on this task.  To accomplish this, make predictions with your model on the test data and then check its performance by examining the MSE and the $R^2$ score. Because we held the test data out from the training process, these predictions give us an idea of how our model performs on unseen data. Then visualize your model's performance by creating a scatter plot of the Y predictions and your Y test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7493853-80bf-428f-b41f-01f731592c25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "Y_pred = ...\n",
    "\n",
    "# Calculate evaluation metrics using scikit-learn's mean_squared_error and r2_score\n",
    "mse = ...\n",
    "r2 = ...\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R² Score: {r2}\")\n",
    "\n",
    "# Visualize predictions vs. actual values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247399fb-9c90-48f5-a2ff-17c51c640631",
   "metadata": {},
   "source": [
    "### Step 6:  Present the Solution\n",
    "In the markdown cell below, discuss how your model performed overall. If the model performed poorly, why do you think it did so? If it performed well, why do you think it did so? What could future analysis include? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7569a53a-a957-44f3-9ead-3b9d6a1ff867",
   "metadata": {},
   "source": [
    "*Your answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a8a7cd-57c9-407b-bff5-2501d49af599",
   "metadata": {},
   "source": [
    "#### *Before we selected our algorithm, we should have looked at the data for evidence of a linear relationship between variables. Let's check now!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fd2efd-e5f4-4f0d-880d-ae4d806a061f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))  # Setting the figure size for better visibility\n",
    "df.plot.scatter(x='albany_DO', y='albany_turbidity', c='DarkBlue')\n",
    "\n",
    "plt.title('Turbidity vs. Dissolved Oxygen at Port of Albany')\n",
    "plt.xlabel('Dissolved Oxygen (ppm)')\n",
    "plt.ylabel('Turbidity (NTU)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c915e91-d2d3-415a-894e-b4e8523511af",
   "metadata": {},
   "source": [
    "### Step 7: Check to see if polynomial regression performs better\n",
    "\n",
    "We assumed linear regression would work well with our data, but this data doesn't look very linear. It's a good reminder of the importance of exploratory analysis. Let's check to see how a polynomial regression performs in comparison. Transform the features for polynomial regression. Use the `PolynomialFeatures` class from the `sklearn.preprocessing` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50961fc0-8274-4987-a17d-f202f832879d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform features to include polynomial terms (degree 2 for quadratic terms)\n",
    "poly = ...\n",
    "X_poly_train = ...\n",
    "X_poly_test = ...\n",
    "\n",
    "# View the transformed feature set (for insight)\n",
    "print(X_poly_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7264fd-ada2-4c15-aeb7-179006197f1d",
   "metadata": {},
   "source": [
    "### Step 8: Fit your model on the polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76b90c2-99c0-4b6f-8257-34b7665b27b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model on polynomial features \n",
    "poly_model = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4208b8a-11fa-4e88-bf0c-7e5bd91d7692",
   "metadata": {},
   "source": [
    "### STEP 9: Evaluate the polynomial regression model \n",
    "- Make predictions with your model and then check the performance of the model.\n",
    "- Check your model performance by looking at the MSE and the $R^2$ score.\n",
    "- Create a scatter plot of the Y polynomial predictions and your Y test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fdd437-19ff-4d8a-907b-0c227fb78f57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make predictions using the polynomial model\n",
    "Y_poly_pred = ...\n",
    "\n",
    "# Calculate evaluation metrics using scikit-learn's mean_squared_error and r2_score\n",
    "poly_mse = ...\n",
    "poly_r2 = ...\n",
    "\n",
    "print(f\"Polynomial Regression Mean Squared Error: {poly_mse}\")\n",
    "print(f\"Polynomial Regression R² Score: {poly_r2}\")\n",
    "\n",
    "# Plot predictions vs actual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dd9bb7-ffbc-429e-bbf4-74f1e7c4e928",
   "metadata": {},
   "source": [
    "### Step 10: Compare your polynomial and linear regression results\n",
    "\n",
    "What differences did you notice between you polynomial regression and linear regression results? Which model performed better? Why do you think this is? Write your answer in the markdown cell below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd04eb66-9b73-4ce5-9b2a-b5ad0f50b64e",
   "metadata": {},
   "source": [
    "*Your answer here.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda 3 (EDS232)",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
