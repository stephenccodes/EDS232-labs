{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Species Distribution Modeling with Bagging \n",
    "Climate change and deforestation are accelerating ecosystem degradation, pushing animal species toward the brink of extinction. Understanding the distribution of animals and the factors that influence their ability to thrive in different environments is critical for conservation efforts. By studying these relationships, biological conservationists can develop informed strategies to protect endangered species and maintain biodiversity across diverse ecosystems.\n",
    "\n",
    "Species are defined by their behavioral, physiological, and ecological attributes, which shape their roles in ecosystems. In turn, ecosystems and their functions are deeply influenced by the species that inhabit them. This reciprocal relationship makes evaluating species' functional diversity and distributions essential for research in biogeography, community ecology, macroevolution, and conservation. Functional diversity is determined by traits such as diet, foraging strata, trophic level, activity cycle, litter size, generation length, habitat breadth, and body mass. These traits influence an animal’s ability to survive and adapt to different climates, playing a crucial role in ecosystem stability.\n",
    "\n",
    "In this lab, we will explore the connections between animal behaviors, functional traits, and species distributions across different climates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Standardizing column names\n",
    "\n",
    "The dataset contains several columns that describe different aspects of bird diets. These column names currently include spaces, colons (:), and special characters, which can make them difficult to work with in code.\n",
    "\n",
    "Load the dataset (BirdTraitData.csv) into a Pandas DataFrame.\n",
    "\n",
    "The 7 column names that start with \"Diet:\" should be renamed to simpler version starting with `Diet_` in a way that conforms with this list of key variables:\n",
    "\n",
    "`AdultBodyMass`, `DietBreadth`, `Diet_Invertebrates`, `Diet_Vertebrates`,`Diet_Fruits`, `Diet_Flowers`, `Diet_Seeds`, `Diet_Plants`, `Diet_Other`, `TrophicLevel`,`ActivityCycle`, `ForagingStratum`, `MigratoryStatus`,`IncubationTime`, `ClutchSize`, `EggLength`, `EggWidth`,`EggMass`, `NestingHabit`,`MaxLongevity`, `Subarid`\n",
    "\n",
    "Then select only that list of 21 key variables. **Print the head of your dataframe.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Encode categorical variables\n",
    "In our dataset, some columns contain categorical (non-numeric) data, such as species names or habitat types that need to be converted to numerical representations. Let's use label encoding to assign a unique number to each category in a column.\n",
    "\n",
    "Encode the data using this process:\n",
    "1. Find all categorical columns in df using `.select_dtypes(include=['object'])`\n",
    "2. Loop through each categorical column and apply `LabelEncoder()`\n",
    "3. Replace the original categorical columns with their encoded values.\n",
    "4. Print the head of your dataframe to ensure that labels were in fact encoded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Defining features, splitting data, and training a bagging classifier\n",
    "Our goal for this analysis is to predict whether a given bird species is present in Subarid climate zones. \n",
    "\n",
    "1. Drop the corresponding variable from the features (X) and define it as the target (y). Then perform the train-test split with 70/30 train/test and a random state of 808.\n",
    "\n",
    "2. Initialize a bagging classifier with 100 trees, `oob_score =True`, `bootstrap = True` and `random_state = 808`.  \n",
    "\n",
    "3. Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Make predictions and evaluate the model\n",
    "\n",
    "1. Generate predictions\n",
    "- Use the trained bagging model to predict values for the test set (`X_test`).\n",
    "\n",
    "2. Calculate the Out-of-Bag (OOB) Score\n",
    "- The OOB score is an internal validation score computed using samples not included in bootstrapped subsets.\n",
    "\n",
    "3. Compute model accuracy\n",
    "- Print the OOB score and the bagging accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Calculate and plot ROC curve\n",
    "\n",
    "- Use `label=f\"Bagging (AUC = {roc_auc_bagging:.2f})\"` to include the AUC value in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now how does the ROC curve look? How does this compare to our classification accuracy metric?  What might be going on? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your anwer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Introducing upsampling\n",
    "\n",
    "The ROC curve indicates that our model is not performing well.  This is a common issue in imbalanced datasets, where one class significantly outnumbers the other. To improve our model’s ability to correctly classify both groups, we will upsample the minority class so that both classes have equal representation in the training set.\n",
    "\n",
    "**Perform upsampling to balance the dataset**\n",
    "1. Separate the majority and minority classes:\n",
    "- Identify which class (0,1) is underrepresented (the minority class) and which is overrepresented (the majority class). \n",
    "- Separate both the `X_train` data and `y_train` data into all majority class and all minority class sets. \n",
    "2. Apply upsampling:\n",
    "- Use `resample()` to create additional synthetic samples of the minority class *with replacement* until it is the same size as the majority class data. Use a random state of 808. \n",
    "3. Combine the balanced classes:\n",
    "Merge the original majority class with the newly upsampled minority class.\n",
    "4. Shuffle the resampled dataset:\n",
    "- Randomly shuffle the data to ensure the model does not learn any unintended patterns from the order of the data. Use a random state of 808 for shuffling both the resampled X and y training data. \n",
    "5. Print the value counts for the resampled y training data to ensure that the data is balanced. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "\n",
    "\n",
    "# Upsample the minority class\n",
    "\n",
    "# Combine majority and upsampled minority class\n",
    "\n",
    "# Shuffle the dataset\n",
    "\n",
    "# Print value counts \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Retrain and evaluate model using balanced data\n",
    "\n",
    "Now that we have addressed the class imbalance by upsampling the minority class, we will retrain the bagging classifier on the newly balanced dataset and evaluate its performance. This will help us determine whether handling class imbalance improves model accuracy and its ability to distinguish between classes. Create a bagging model using your balanced data. Use a random state of 808. Print the accuracy and and ROC Curve for this new model with balanced data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did this second model, trained on balanced data, do in comparison to the first on the accuracy and AUC metrics.  How should we interpret those results?  Did the upscaling prove useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Analyzing feature importance with permutation importance\n",
    "\n",
    "Understanding which bird traits contribute the most to our model’s predictions is crucial for interpreting results. We covered in lecture how the results of ensemble methods are harder to interpret than a single decision tree.  But we do have some tools to do it.  In this step, we will compute permutation importance, which measures the impact of each trait by shuffling its values and observing the effect on model performance. This will help us identify which functional traits—such as diet, body mass, or habitat breadth—play the biggest role in predicting whether a species is found in a subarid environment.\n",
    "\n",
    "Use `permutation_importance()` to calculate the importance values.  You'll need to pass it the model, the feature and target test data, and an n_repeats value of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What features are most important in our model of species distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda 3 (EDS232)",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
